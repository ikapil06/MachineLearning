{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e59605a3",
   "metadata": {},
   "source": [
    "# Hotel Reservation Cancellation Prediction\n",
    "\n",
    "This notebook demonstrates an end-to-end machine learning workflow for predicting hotel booking cancellations. The process includes data loading, cleaning, basic exploratory data analysis (EDA), model training, evaluation, and generating predictions for a test dataset. The goal is to predict whether a given reservation will be cancelled (1) or not cancelled (0).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53472f24",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfb3c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Enable inline plots for Jupyter notebooks\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddccc27",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01844248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the training and test datasets\n",
    "train_path = 'train.csv'\n",
    "test_path = 'test.csv'\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "# Display the shapes of the datasets\n",
    "train_df_shape = train_df.shape\n",
    "test_df_shape = test_df.shape\n",
    "train_df_shape, test_df_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a93c85",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919fe0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows from both datasets\n",
    "train_df = train_df.drop_duplicates().reset_index(drop=True)\n",
    "test_df = test_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Fill missing numerical values with the median of the column\n",
    "for col in train_df.select_dtypes(include=[np.number]).columns:\n",
    "    if train_df[col].isnull().any():\n",
    "        train_df[col].fillna(train_df[col].median(), inplace=True)\n",
    "\n",
    "for col in test_df.select_dtypes(include=[np.number]).columns:\n",
    "    if test_df[col].isnull().any():\n",
    "        test_df[col].fillna(test_df[col].median(), inplace=True)\n",
    "\n",
    "# Fill missing categorical values with the mode of the column\n",
    "for col in train_df.select_dtypes(include=['object']).columns:\n",
    "    if train_df[col].isnull().any():\n",
    "        train_df[col].fillna(train_df[col].mode()[0], inplace=True)\n",
    "\n",
    "for col in test_df.select_dtypes(include=['object']).columns:\n",
    "    if test_df[col].isnull().any():\n",
    "        test_df[col].fillna(test_df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Show summary of cleaned training dataset\n",
    "train_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bd30e2",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2855712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first five rows of the training data\n",
    "train_df_head = train_df.head()\n",
    "train_df_head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2e5e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics for numerical columns\n",
    "train_df_describe = train_df.describe()\n",
    "train_df_describe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cbca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution and bar plot\n",
    "class_counts = train_df['booking_status'].value_counts()\n",
    "print(\"Class distribution (counts):\")\n",
    "print(class_counts)\n",
    "\n",
    "# Bar plot using matplotlib for the target distribution\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.bar(class_counts.index.astype(str), class_counts.values)\n",
    "plt.title(\"Target class distribution\")\n",
    "plt.xlabel(\"booking_status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa464503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix and heatmap for numeric features\n",
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "if len(numeric_cols) > 1:\n",
    "    corr = train_df[numeric_cols].corr()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(corr, interpolation='nearest', aspect='auto')\n",
    "    plt.colorbar()\n",
    "    plt.xticks(range(len(numeric_cols)), numeric_cols, rotation=45, ha='right')\n",
    "    plt.yticks(range(len(numeric_cols)), numeric_cols)\n",
    "    plt.title(\"Correlation heatmap (numeric features)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough numeric features for a correlation matrix.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2ee6e5",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e68bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = train_df.drop(columns=['booking_status'])\n",
    "y = train_df['booking_status']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "# Preprocessor for One-Hot encoding categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "        ('num', 'passthrough', numerical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Create the model pipeline with RandomForestClassifier\n",
    "clf = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestClassifier(\n",
    "            n_estimators=300,\n",
    "            random_state=42,\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "val_preds = clf.predict(X_val)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "val_accuracy = accuracy_score(y_val, val_preds)\n",
    "val_precision = precision_score(y_val, val_preds)\n",
    "val_recall = recall_score(y_val, val_preds)\n",
    "val_f1 = f1_score(y_val, val_preds)\n",
    "\n",
    "# Display metrics\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "print(\"Validation Precision:\", val_precision)\n",
    "print(\"Validation Recall:\", val_recall)\n",
    "print(\"Validation F1 Score:\", val_f1)\n",
    "print(\"Classification Report: \", classification_report(y_val, val_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020a801b",
   "metadata": {},
   "source": [
    "## Train on Full Data and Predict on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6886c8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the full training data\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Predict on the cleaned test data\n",
    "preds = clf.predict(test_df)\n",
    "\n",
    "# Map numeric predictions to human-readable labels\n",
    "label_map = {1: 'Canceled', 0: 'Not_Canceled'}\n",
    "pred_labels = [label_map[int(p)] for p in preds]\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'booking_status': pred_labels\n",
    "})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the submission for confirmation\n",
    "submission_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7327e859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
